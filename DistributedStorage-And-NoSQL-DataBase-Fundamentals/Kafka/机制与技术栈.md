[toc]
# Introduction

Kafka它本质上是一个消息系统，它提供了常用的消息系统的功能集，但是它的设计更加独特，原本开发自LinkedIn，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。

![](http://images0.cnblogs.com/blog2015/666745/201505/261159103182564.png)

首先，Kafka可以应用于消息系统，比如，当下较为热门的消息推送，这些消息推送系统的消息源，可以使用Kafka作为系统的核心组建来完成消息的生产 和消息的消费。然后是网站的行迹，我们可以将企业的Portal，用户的操作记录等信息发送到Kafka中，按照实际业务需求，可以进行实时监控，或者做离线处理等。最后，一个是日志收集，类似于Flume套件这样的日志收集系统，但Kafka的设计架构采用push/pull，适合异构集群，Kafka 可以批量提交消息，对Producer来说，在性能方面基本上是无消耗的，而在Consumer端中，我们可以使用HDFS这类的分布式文件存储系统进行存储。

## Features:特征

Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：

- 以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out：支持在线水平扩展。

**关键概念**

| Concepts    | Function                                 |
| ----------- | ---------------------------------------- |
| Topic       | 用于划分Message的逻辑概念，一个Topic可以分布在多个Broker上。  |
| Partition   | 是Kafka中横向扩展和一切并行化的基础，每个Topic都至少被切分为1个Partition。 |
| Offset      | 消息在Partition中的编号，编号顺序不跨Partition(在Partition内有序)。 |
| Consumer    | 用于从Broker中取出/消费Message。                  |
| Producer    | 用于往Broker中发送/生产Message。                  |
| Replication | Kafka支持以Partition为单位对Message进行冗余备份，每个Partition都可以配置至少1个Replication(当仅1个Replication时即仅该Partition本身)。 |
| Leader      | 每个Replication集合中的Partition都会选出一个唯一的Leader，所有的读写请求都由Leader处理。其他Replicas从Leader处把数据更新同步到本地。 |
| Broker      | Kafka中使用Broker来接受Producer和Consumer的请求，并把Message持久化到本地磁盘。每个Cluster当中会选举出一个Broker来担任Controller，负责处理Partition的Leader选举，协调Partition迁移等工作。 |
| ISR         | In-Sync Replica,是Replicas的一个子集，表示目前Alive且与Leader能够“Catch-up”的Replicas集合。由于读写都是首先落到Leader上，所以一般来说通过同步机制从Leader上拉取数据的Replica都会和Leader有一些延迟(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该Replica踢出ISR。每个Leader Partition都有它自己独立的ISR。 |

**设计思想**

| Concepts      | Function                                 |
| ------------- | ---------------------------------------- |
| Consumergroup | 各个consumer可以组成一个组，每个消息只能被组中的一个consumer消费，如果一个消息可以被多个consumer消费的话，那么这些consumer必须在不同的组。 |
| 消息状态          | 在Kafka中，消息的状态被保存在consumer中，broker不会关心哪个消息被消费了被谁消费了，只记录一个offset值（指向partition中下一个要被消费的消息位置），这就意味着如果consumer处理不好的话，broker上的一个消息可能会被消费多次。 |
| 消息持久化         | Kafka中会把消息持久化到本地文件系统中，并且保持极高的效率。         |
| 消息有效期         | Kafka会长久保留其中的消息，以便consumer可以多次消费，当然其中很多细节是可配置的。 |
| 批量发送          | Kafka支持以消息集合为单位进行批量发送，以提高push效率。         |
| push-and-pull | Kafka中的Producer和consumer采用的是push-and-pull模式，即Producer只管向broker push消息，consumer只管从broker pull消息，两者对消息的生产和消费是异步的。 |
| Broker之间的关系   | 不是主从关系，各个broker在集群中地位一样，我们可以随意的增加或删除任何一个broker节点。 |
| 负载均衡          | Kafka提供了一个 metadata API来管理broker之间的负载（对Kafka0.8.x而言，对于0.7.x主要靠zookeeper来实现负载均衡）。 |
| 同步异步          | Producer采用异步push方式，极大提高Kafka系统的吞吐率（可以通过参数控制是采用同步还是异步方式）。 |
| 分区机制partition | Kafka的broker端支持消息分区，Producer可以决定把消息发到哪个分区，在一个分区中消息的顺序就是Producer发送消息的顺序，一个主题中可以有多个分区，具体分区的数量是可配置的。分区的意义很重大，后面的内容会逐渐体现。 |

## Use Cases:使用场景

### Message Broker:用于异构服务之间的消息传递

### Statistic Analysis:统计分析
活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。
近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。
### Stream Processing:流计算





# Quick Start

## Installation
本假设你本机还没有安装任何的Zookeeper节点或者Kafka节点，首先我们需要下载Kafka源代码然后将其解压缩:
```
> tar -xzf kafka_2.11-0.9.0.0.tgz
> cd kafka_2.11-0.9.0.0
```
Kafka默认使用ZooKeeper作为服务协调器，并且Kafka内置了一个ZooKeeper的运行脚本，可以让你快速地启动允许一个单节点的ZooKeeper实例:
```
> bin/zookeeper-server-start.sh config/zookeeper.properties
[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
```
然后启动Kafka服务器:

```
> bin/kafka-server-start.sh config/server.properties
[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)
...
```
## Usage
在启动了Kafka服务器之后，我们首先来尝试创建一个名为`test`的主题，设置只有一个Partition与一个Replica。
```
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```
然后我们在查询主题列表的时候就可以看到该主题了:
```
> bin/kafka-topics.sh --list --zookeeper localhost:2181
test
```
除了手动地指定创建主题，我们也可以配置Brokers在收到不存在的主题的时候自动创建该主题。在Topics创建好之后，就可以通过其来发送消息。Kafka为我们提供了一个命令行工具，可以允许我们从某个文件或者其他标准的输入流中抓取数据然后将其以消息形式发送到Kafka集群，默认情况下每个单独的行会被认为是一条单独的消息。
```
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
```
消息发送完毕之后，我们需要设置Consumer端来读取消息，Kafka同样为我们提供了这样一个便捷的命令行工具，
```
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
This is a message
This is another message
```
如果你在不同的命令行中分别运行上述命令，那么你的Consumer已经能够接收到这些数据了。

# Overview:为何Kafka快？
Kafka速度的秘诀在于，它把所有的消息都变成一个的文件。通过mmap提高I/O速度，写入数据的时候它是末尾添加所以速度最优；读取数据的时候配合sendfile直接暴力输出。阿里的RocketMQ也是这种模式，只不过是用Java写的。

## Terminology

- **Broker**:Kafka集群包含一个或多个服务器，这种服务器被称为broker
- **Topic**:每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处）
- **Partition**:parition是物理上的概念，每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件
- **Producer**:负责发布消息到Kafka broker
- **Consumer**:消费消息。每个consumer属于一个特定的consumer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。


## Producer
Producer负责向Kafka中提交数据，Cluster会将所有收到的消息写入到硬盘中而绝不会丢失数据。在这其中，Kafka为了优化写入速度采用了顺序写入与MMFile。
### 顺序写入
![](http://images0.cnblogs.com/blog2015/666745/201505/261038057408774.png)
因为硬盘是机械结构，每次读写都会寻址->写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最“讨厌”随机I/O，最喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。上图就展示了Kafka是如何写入数据的，每一个Partition其实都是一个文件，收到消息后Kafka会把数据插入到文件末尾（虚框部分）。这种方法有一个缺陷——没有办法删除数据，所以Kafka是不会删除数据的，它会把所有的数据都保留下来，每个消费者（Consumer）对每个Topic都有一个offset用来表示读取到了第几条数据。
![](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBaNlc0QmCianUo0EjdU7JovO4REAw7AP9fjtJ6vLbmUtmrROEA1ibt662Q/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
上图中有两个消费者，Consumer1有两个offset分别对应Partition0、Partition1（假设每一个Topic一个 Partition）；Consumer2有一个offset对应Partition2。这个offset是由客户端SDK负责保存的，Kafka的 Broker完全无视这个东西的存在；一般情况下SDK会把它保存到zookeeper里面。(所以需要给Consumer提供zookeeper的地 址)。
如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据。一是基于时间，二是基于partition文件大小。具体配置可以参看它的配置文档。
### Memory Mapped Files
即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高I/O效率。
Memory Mapped Files(后面简称mmap)也被翻译成内存映射文件，在64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。
![](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBaTnnCQ39f6PmJBogZBicf67rxULWBd0icU0dK2LMLCib7BZXibJvY1nu4SQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。使用这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）也有一个很明显的缺陷——不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫同步(sync)；写入mmap之后立即返回Producer不调用flush叫异步(async)。mmap其实是Linux中的一个函数就是用来实现内存映射的，谢谢Java NIO，它给我提供了一个mappedbytebuffer类可以用来实现内存映射（所以是沾了Java的光才可以如此神速和Scala没关系！！）

## Consumer With Zero Copy
ZeroMQ完全没有任何服务器节点，也不会使用硬盘，按照道理说它应该比Kafka快。可是实际测试下来它的速度还是被Kafka“吊打”。“一个用硬盘的比用内存的快”，这绝对违反常识；如果这种事情发生说明——它作弊了。
没错，Kafka“作弊”。无论是顺序写入还是mmap其实都是作弊的准备工作。仔细想一下，一个Web Server传送一个静态文件，如何优化？答案是zero copy。传统模式下我们从硬盘读取一个文件是这样的

![img](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBauHTEX7RsViavUiaLSDOvgIWqFGiaDkMZnI9b7u3bJeOG7P0qgqTazIsRg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
先复制到内核空间（read是系统调用，放到了DMA，所以用内核空间），然后复制到用户空间(1,2)；从用户空间重新复制到内核空间（你用的socket是系统调用，所以它也有自己的内核空间），最后发送给网卡（3、4）。

![img](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBacFSACPXxQXGXRaQuLwGQOb8eWfAsBxZctvFl2WRMySOicOGaLtqiaNRQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
Zero Copy中直接从内核空间（DMA的）到内核空间（Socket的），然后发送网卡。
这个技术非常普遍，The C10K problem 里面也有很详细的介绍，Nginx也是用的这种技术，稍微搜一下就能找到很多资料。

Java的NIO提供了FileChannle，它的transferTo、transferFrom方法就是Zero Copy。
Kafka把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候Kafka直接把“文件”发送给消费者。这就是秘诀所在，比如：10W的消息组合在一起是10MB的数据量，然后Kafka用类似于发文件的方式直接扔出去了，如果消费者和生产者之间的网络非常好（只要网络稍微正常一点10MB根本不是事。。。家里上网都是100Mbps的带宽了），10MB可能只需要1s。所以答案是——10W的TPS，Kafka每秒钟处理了10W条消息。
可能你说：不可能把整个文件发出去吧？里面还有一些不需要的消息呢？是的，Kafka作为一个“高级作弊分子”自然要把作弊做的有逼格。Zero Copy对应的是sendfile这个函数（以Linux为例），这个函数接受

    out_fd作为输出（一般及时socket的句柄）

    in_fd作为输入文件句柄

    off_t表示in_fd的偏移（从哪里开始读取）

    size_t表示读取多少个

没错，Kafka是用mmap作为文件读写方式的，它就是一个文件句柄，所以直接把它传给sendfile；偏移也好解决，用户会自己保持这个offset，每次请求都会发送这个offset。（还记得吗？放在zookeeper中的）；数据量更容易解决了，如果消费者想要更快，就全部扔给消费者。如果这样做一般情况下消费者肯定直接就被压死了；所以Kafka提供了的两种方式——Push，我全部扔给你了，你死了不管我的事情；Pull，好吧你告诉我你需要多少个，我给你多少个。












![](http://153.3.251.190:11900/kafka)