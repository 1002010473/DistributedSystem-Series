![default](https://user-images.githubusercontent.com/5803001/45228854-de88b400-b2f6-11e8-9ab0-d393ed19f21f.png)

# Kafka 机制与技术栈

Kafka 它本质上是一个消息系统，它提供了常用的消息系统的功能集，但是它的设计更加独特，原本开发自 LinkedIn，用作 LinkedIn 的活动流(Activity Stream)和运营数据处理管道(Pipeline)的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。

![](http://images0.cnblogs.com/blog2015/666745/201505/261159103182564.png)

首先，Kafka 可以应用于消息系统，比如，当下较为热门的消息推送，这些消息推送系统的消息源，可以使用 Kafka 作为系统的核心组建来完成消息的生产 和消息的消费。然后是网站的行迹，我们可以将企业的 Portal，用户的操作记录等信息发送到 Kafka 中，按照实际业务需求，可以进行实时监控，或者做离线处理等。最后，一个是日志收集，类似于 Flume 套件这样的日志收集系统，但 Kafka 的设计架构采用 push/pull，适合异构集群，Kafka 可以批量提交消息，对 Producer 来说，在性能方面基本上是无消耗的，而在 Consumer 端中，我们可以使用 HDFS 这类的分布式文件存储系统进行存储。

## Features:特征

Kafka 是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：

- 以时间复杂度为 O(1)的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
- 支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out：支持在线水平扩展。

**关键概念**

| Concepts    | Function                                                                                                                                                                                                                                                                                                                                      |
| ----------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Topic       | 用于划分 Message 的逻辑概念，一个 Topic 可以分布在多个 Broker 上。                                                                                                                                                                                                                                                                            |
| Partition   | 是 Kafka 中横向扩展和一切并行化的基础，每个 Topic 都至少被切分为 1 个 Partition。                                                                                                                                                                                                                                                             |
| Offset      | 消息在 Partition 中的编号，编号顺序不跨 Partition(在 Partition 内有序)。                                                                                                                                                                                                                                                                      |
| Consumer    | 用于从 Broker 中取出/消费 Message。                                                                                                                                                                                                                                                                                                           |
| Producer    | 用于往 Broker 中发送/生产 Message。                                                                                                                                                                                                                                                                                                           |
| Replication | Kafka 支持以 Partition 为单位对 Message 进行冗余备份，每个 Partition 都可以配置至少 1 个 Replication(当仅 1 个 Replication 时即仅该 Partition 本身)。                                                                                                                                                                                         |
| Leader      | 每个 Replication 集合中的 Partition 都会选出一个唯一的 Leader，所有的读写请求都由 Leader 处理。其他 Replicas 从 Leader 处把数据更新同步到本地。                                                                                                                                                                                               |
| Broker      | Kafka 中使用 Broker 来接受 Producer 和 Consumer 的请求，并把 Message 持久化到本地磁盘。每个 Cluster 当中会选举出一个 Broker 来担任 Controller，负责处理 Partition 的 Leader 选举，协调 Partition 迁移等工作。                                                                                                                                 |
| ISR         | In-Sync Replica,是 Replicas 的一个子集，表示目前 Alive 且与 Leader 能够“Catch-up”的 Replicas 集合。由于读写都是首先落到 Leader 上，所以一般来说通过同步机制从 Leader 上拉取数据的 Replica 都会和 Leader 有一些延迟(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该 Replica 踢出 ISR。每个 Leader Partition 都有它自己独立的 ISR。 |

**设计思想**

| Concepts           | Function                                                                                                                                                                                                                             |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Consumergroup      | 各个 consumer 可以组成一个组，每个消息只能被组中的一个 consumer 消费，如果一个消息可以被多个 consumer 消费的话，那么这些 consumer 必须在不同的组。                                                                                   |
| 消息状态           | 在 Kafka 中，消息的状态被保存在 consumer 中，broker 不会关心哪个消息被消费了被谁消费了，只记录一个 offset 值(指向 partition 中下一个要被消费的消息位置)，这就意味着如果 consumer 处理不好的话，broker 上的一个消息可能会被消费多次。 |
| 消息持久化         | Kafka 中会把消息持久化到本地文件系统中，并且保持极高的效率。                                                                                                                                                                         |
| 消息有效期         | Kafka 会长久保留其中的消息，以便 consumer 可以多次消费，当然其中很多细节是可配置的。                                                                                                                                                 |
| 批量发送           | Kafka 支持以消息集合为单位进行批量发送，以提高 push 效率。                                                                                                                                                                           |
| push-and-pull      | Kafka 中的 Producer 和 consumer 采用的是 push-and-pull 模式，即 Producer 只管向 broker push 消息，consumer 只管从 broker pull 消息，两者对消息的生产和消费是异步的。                                                                 |
| Broker 之间的关系  | 不是主从关系，各个 broker 在集群中地位一样，我们可以随意的增加或删除任何一个 broker 节点。                                                                                                                                           |
| 负载均衡           | Kafka 提供了一个 metadata API 来管理 broker 之间的负载(对 Kafka0.8.x 而言，对于 0.7.x 主要靠 zookeeper 来实现负载均衡)。                                                                                                             |
| 同步异步           | Producer 采用异步 push 方式，极大提高 Kafka 系统的吞吐率(可以通过参数控制是采用同步还是异步方式)。                                                                                                                                   |
| 分区机制 partition | Kafka 的 broker 端支持消息分区，Producer 可以决定把消息发到哪个分区，在一个分区中消息的顺序就是 Producer 发送消息的顺序，一个主题中可以有多个分区，具体分区的数量是可配置的。分区的意义很重大，后面的内容会逐渐体现。                |

## Use Cases:使用场景

### Message Broker:用于异构服务之间的消息传递

### Statistic Analysis:统计分析

活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量(Page View)、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据(CPU、IO 使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。
近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。

### Stream Processing:流计算

# Quick Start

## Installation

本假设你本机还没有安装任何的 Zookeeper 节点或者 Kafka 节点，首先我们需要下载 Kafka 源代码然后将其解压缩:

```
> tar -xzf kafka_2.11-0.9.0.0.tgz
> cd kafka_2.11-0.9.0.0
```

Kafka 默认使用 ZooKeeper 作为服务协调器，并且 Kafka 内置了一个 ZooKeeper 的运行脚本，可以让你快速地启动允许一个单节点的 ZooKeeper 实例:

```
> bin/zookeeper-server-start.sh config/zookeeper.properties
[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
```

然后启动 Kafka 服务器:

```
> bin/kafka-server-start.sh config/server.properties
[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)
...
```

## Usage

在启动了 Kafka 服务器之后，我们首先来尝试创建一个名为`test`的主题，设置只有一个 Partition 与一个 Replica。

```
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```

然后我们在查询主题列表的时候就可以看到该主题了:

```
> bin/kafka-topics.sh --list --zookeeper localhost:2181
test
```

除了手动地指定创建主题，我们也可以配置 Brokers 在收到不存在的主题的时候自动创建该主题。在 Topics 创建好之后，就可以通过其来发送消息。Kafka 为我们提供了一个命令行工具，可以允许我们从某个文件或者其他标准的输入流中抓取数据然后将其以消息形式发送到 Kafka 集群，默认情况下每个单独的行会被认为是一条单独的消息。

```
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
```

消息发送完毕之后，我们需要设置 Consumer 端来读取消息，Kafka 同样为我们提供了这样一个便捷的命令行工具，

```
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
This is a message
This is another message
```

如果你在不同的命令行中分别运行上述命令，那么你的 Consumer 已经能够接收到这些数据了。

# Overview:为何 Kafka 快？

Kafka 速度的秘诀在于，它把所有的消息都变成一个的文件。通过 mmap 提高 I/O 速度，写入数据的时候它是末尾添加所以速度最优；读取数据的时候配合 sendfile 直接暴力输出。阿里的 RocketMQ 也是这种模式，只不过是用 Java 写的。

## Terminology

- **Broker**:Kafka 集群包含一个或多个服务器，这种服务器被称为 broker
- **Topic**:每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 topic。(物理上不同 topic 的消息分开存储，逻辑上一个 topic 的消息虽然保存于一个或多个 broker 上但用户只需指定消息的 topic 即可生产或消费数据而不必关心数据存于何处)
- **Partition**:parition 是物理上的概念，每个 topic 包含一个或多个 partition，创建 topic 时可指定 parition 数量。每个 partition 对应于一个文件夹，该文件夹下存储该 partition 的数据和索引文件
- **Producer**:负责发布消息到 Kafka broker
- **Consumer**:消费消息。每个 consumer 属于一个特定的 consumer group(可为每个 consumer 指定 group name，若不指定 group name 则属于默认的 group)。使用 consumer high level API 时，同一 topic 的一条消息只能被同一个 consumer group 内的一个 consumer 消费，但多个 consumer group 可同时消费这一消息。

## Producer

Producer 负责向 Kafka 中提交数据，Cluster 会将所有收到的消息写入到硬盘中而绝不会丢失数据。在这其中，Kafka 为了优化写入速度采用了顺序写入与 MMFile。

### 顺序写入

![](http://images0.cnblogs.com/blog2015/666745/201505/261038057408774.png)
因为硬盘是机械结构，每次读写都会寻址->写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最“讨厌”随机 I/O，最喜欢顺序 I/O。为了提高读写硬盘的速度，Kafka 就是使用顺序 I/O。上图就展示了 Kafka 是如何写入数据的，每一个 Partition 其实都是一个文件，收到消息后 Kafka 会把数据插入到文件末尾(虚框部分)。这种方法有一个缺陷——没有办法删除数据，所以 Kafka 是不会删除数据的，它会把所有的数据都保留下来，每个消费者(Consumer)对每个 Topic 都有一个 offset 用来表示读取到了第几条数据。
![](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBaNlc0QmCianUo0EjdU7JovO4REAw7AP9fjtJ6vLbmUtmrROEA1ibt662Q/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
上图中有两个消费者，Consumer1 有两个 offset 分别对应 Partition0、Partition1(假设每一个 Topic 一个 Partition)；Consumer2 有一个 offset 对应 Partition2。这个 offset 是由客户端 SDK 负责保存的，Kafka 的 Broker 完全无视这个东西的存在；一般情况下 SDK 会把它保存到 zookeeper 里面。(所以需要给 Consumer 提供 zookeeper 的地 址)。
如果不删除硬盘肯定会被撑满，所以 Kakfa 提供了两种策略来删除数据。一是基于时间，二是基于 partition 文件大小。具体配置可以参看它的配置文档。

### Memory Mapped Files

即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以 Kafka 的数据并不是实时的写入硬盘，它充分利用了现代操作系统分页存储来利用内存提高 I/O 效率。
Memory Mapped Files(后面简称 mmap)也被翻译成内存映射文件，在 64 位操作系统中一般可以表示 20G 的数据文件，它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上(操作系统在适当的时候)。
![](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBaTnnCQ39f6PmJBogZBicf67rxULWBd0icU0dK2LMLCib7BZXibJvY1nu4SQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
通过 mmap，进程像读写硬盘一样读写内存(当然是虚拟机内存)，也不必关心内存的大小有虚拟内存为我们兜底。使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销(调用文件的 read 会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。)也有一个很明显的缺陷——不可靠，写到 mmap 中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用 flush 的时候才把数据真正的写到硬盘。Kafka 提供了一个参数——producer.type 来控制是不是主动 flush，如果 Kafka 写入到 mmap 之后就立即 flush 然后再返回 Producer 叫同步(sync)；写入 mmap 之后立即返回 Producer 不调用 flush 叫异步(async)。mmap 其实是 Linux 中的一个函数就是用来实现内存映射的，谢谢 Java NIO，它给我提供了一个 mappedbytebuffer 类可以用来实现内存映射(所以是沾了 Java 的光才可以如此神速和 Scala 没关系！！)

## Consumer With Zero Copy

ZeroMQ 完全没有任何服务器节点，也不会使用硬盘，按照道理说它应该比 Kafka 快。可是实际测试下来它的速度还是被 Kafka“吊打”。“一个用硬盘的比用内存的快”，这绝对违反常识；如果这种事情发生说明——它作弊了。
没错，Kafka“作弊”。无论是顺序写入还是 mmap 其实都是作弊的准备工作。仔细想一下，一个 Web Server 传送一个静态文件，如何优化？答案是 zero copy。传统模式下我们从硬盘读取一个文件是这样的

![img](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBauHTEX7RsViavUiaLSDOvgIWqFGiaDkMZnI9b7u3bJeOG7P0qgqTazIsRg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
先复制到内核空间(read 是系统调用，放到了 DMA，所以用内核空间)，然后复制到用户空间(1,2)；从用户空间重新复制到内核空间(你用的 socket 是系统调用，所以它也有自己的内核空间)，最后发送给网卡(3、4)。

![img](http://mmbiz.qpic.cn/mmbiz/nfxUjuI2HXjiahgInoFXLfVoghamdPiaBacFSACPXxQXGXRaQuLwGQOb8eWfAsBxZctvFl2WRMySOicOGaLtqiaNRQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
Zero Copy 中直接从内核空间(DMA 的)到内核空间(Socket 的)，然后发送网卡。
这个技术非常普遍，The C10K problem 里面也有很详细的介绍，Nginx 也是用的这种技术，稍微搜一下就能找到很多资料。

Java 的 NIO 提供了 FileChannle，它的 transferTo、transferFrom 方法就是 Zero Copy。
Kafka 把所有的消息都存放在一个一个的文件中，当消费者需要数据的时候 Kafka 直接把“文件”发送给消费者。这就是秘诀所在，比如：10W 的消息组合在一起是 10MB 的数据量，然后 Kafka 用类似于发文件的方式直接扔出去了，如果消费者和生产者之间的网络非常好(只要网络稍微正常一点 10MB 根本不是事。。。家里上网都是 100Mbps 的带宽了)，10MB 可能只需要 1s。所以答案是——10W 的 TPS，Kafka 每秒钟处理了 10W 条消息。
可能你说：不可能把整个文件发出去吧？里面还有一些不需要的消息呢？是的，Kafka 作为一个“高级作弊分子”自然要把作弊做的有逼格。Zero Copy 对应的是 sendfile 这个函数(以 Linux 为例)，这个函数接受

    out_fd作为输出(一般及时socket的句柄)

    in_fd作为输入文件句柄

    off_t表示in_fd的偏移(从哪里开始读取)

    size_t表示读取多少个

没错，Kafka 是用 mmap 作为文件读写方式的，它就是一个文件句柄，所以直接把它传给 sendfile；偏移也好解决，用户会自己保持这个 offset，每次请求都会发送这个 offset。(还记得吗？放在 zookeeper 中的)；数据量更容易解决了，如果消费者想要更快，就全部扔给消费者。如果这样做一般情况下消费者肯定直接就被压死了；所以 Kafka 提供了的两种方式——Push，我全部扔给你了，你死了不管我的事情；Pull，好吧你告诉我你需要多少个，我给你多少个。

![](http://153.3.251.190:11900/kafka)
