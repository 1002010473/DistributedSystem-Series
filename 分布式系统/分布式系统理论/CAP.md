# CAP

可用性和一致性的冲突：CAP 理论。

![](https://ww1.sinaimg.cn/large/007rAy9hly1g0pfuxwmxuj30h40i6dgg.jpg)

分布式场景下比较著名的难题就是 CAP 定理。CAP 定理认为，在分布式系统中，系统的一致性（Consistency）、可用性（Availability）、分区容忍性（Partition tolerance），三者不可能同时兼顾。在分布式系统中，由于网络通信的不稳定性，分区容忍性是必须要保证的，因此在设计应用的时候就需要在一致性和可用性之间权衡选择。互联网应用比企业级应用更加偏向保持可用性，因此通常用最终一致性代替传统事务的 ACID 强一致性。

分布式环境下，我们无法保证网络的正常连接和信息的传送，于是发展出了 CAP/FLP/DLS 这三个重要的理论：

- CAP:分布式计算系统不可能同时确保一致性（Consistency）、可用性（Availablity）和分区容忍性（Partition）。

- FLP：在异步环境中，如果节点间的网络延迟没有上限，只要有一个恶意的节点存在，就没有算法能在有限的时间内达成共识。

- DLS: 网络延时可以保证小于已知时间的同步模型中的协议可以 100% 容错，网络延时有界限但是我们并不知道在哪里的部分同步网络模型可以容忍拜占庭错误，异步模型中的确定性的协议（没有网络延时上限）不能容错。

多数情况下，其实我们也并非一定要求强一致性，部分业务可以容忍一定程度的延迟一致，所以为了兼顾效率，发展出来了最终一致性理论 BASE，BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）

- 基本可用(Basically Available)：基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。

- 软状态(Soft State)：软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。

- 最终一致性(Eventual Consistency)：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。

分布式架构的核心就在一致性的实现和妥协，那么如何设计一套算法来保证不同节点之间的通信和数据达到无限趋向一致性，就非常重要了。保证不同节点在充满不确定性网络环境下能达成相同副本的一致性是非常困难的。一致性问题的解法就是分布式时钟，分布式事务与一致性算法。

首先需要考虑分布式时钟问题，最初使用网络时间协议（NTP）试图来解决不同节点之间的标准时间，但是 NTP 本身表现并不如人意，所以我们又构造除了逻辑时钟，最后改进为向量时钟。有了衡量时间的工具，解决顺序问题自然就是水到渠成了。因为整个分布式的理论基础就是如何协商不同节点的一致性问题，而顺序则是一致性理论的基本概念。

CALM 原则的全称是 Consistency and Logical Monotonicity ，主要描述的是分布式系统中单调逻辑与一致性的关系，它的内容如下，参考 consistency as logical monotonicity

- 在分布式系统中，单调的逻辑都能保证 “最终一致性”，这个过程中不需要依赖中心节点的调度。
- 任意分布式系统，如果所有的非单调逻辑都有中心节点调度，那么这个分布式系统就可以实现最终“一致性”。

一致性算法的前提是数据结构，或者说一切算法的根基都是数据结构，设计良好的数据结构加上精妙的算法可以高效的解决现实的问题。分布式系统的数据结构 CRDT(Conflict-Free Replicated Data Types) 即是分布式系统中被广泛采用的数据结构：

- 基于状态(state-based)：即将各个节点之间的 CRDT 数据直接进行合并，所有节点都能最终合并到同一个状态，数据合并的顺序不会影响到最终的结果。

- 基于操作(operation-based)：将每一次对数据的操作通知给其他节点。只要节点知道了对数据的所有操作（收到操作的顺序可以是任意的），就能合并到同一个状态。

我们需要来关注一下分布式系统的一些重要的协议 HATs(Highly Available Transactions)，ZAB(Zookeeper Atomic Broadcast)，这些往往是基于业界主流的一致性算法，譬如 Paxos, Raft 以及 Gossip 等。

# CAP 定理

CAP 定理又被称作布鲁尔定理，是加州大学的计算机科学家布鲁尔在 2000 年提出的一个猜想。

2002 年，麻省理工学院的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为分布式计算领域公认的一个定理。

布鲁尔在提出 CAP 猜想时并没有具体定义 Consistency、Availability、Partition Tolerance 这 3 个词的含义，不同资料的具体定义也有差别。

![](http://mmbiz.qpic.cn/mmbiz/sXiaukvjR0RDkMrYwKrTAtVSKwpEMpjBdheh5BLQ96j3ZHjVGxQHUdvG6diatAd8YBiblUd0RAm7BcGOYYyZYrEDQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1)

## Consistency

一致性一致性又称为原子性或者事务性，对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。一致性表示一个事务的操作是不可分割的，要不然这个事务完成，要不然这个事务不完成，不会出现这个事务完成了一半这样的情况，也就不会读取到脏数据。传统的 ACID 数据库是很少存在一致性问题的，因为数据的单点原因，数据的存取又具有良好的事务性，不会出现读写的不一致。

而在分布式系统中，经常出现的一个数据不具有一致性的情况是读写数据时缺乏一致性。比如两个节点数据冗余，第一个节点有一个写操作，数据更新以后没有有效的使得第二个节点更新数据，在读取第二个节点的时候就会出现不一致的问题出现。这里并不是强调同一时刻拥有相同的数据，对于系统执行事务来说，在事务执行过程中，系统其实处于一个不一致的状态，不同的节点的数据并不完全一致。一致性强调客户端读操作能够获取最新的写操作结果，是因为事务在执行过程中，客户端是无法读取到未提交的数据的。只有等到事务提交后，客户端才能读取到事务写入的数据，而如果事务失败则会进行回滚，客户端也不会读取到事务中间写入的数据。

## Availability

Availability 可用性好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。可用性通常情况下可用性和分布式数据冗余，负载均衡等有着很大的关联。非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。

这里强调的是合理的响应，不能超时，不能出错。注意并没有说“正确”的结果，例如，应该返回 100 但实际上返回了 90，肯定是不正确的结果，但可以是一个合理的结果。

## Partition Tolerance

当出现网络分区后，系统能够继续“履行职责”。

这里网络分区是指：一个分布式系统里面，节点组成的网络本来应该是连通的。

然而可能因为一些故障（节点间网络连接断开、节点宕机），使得有些节点之间不连通了，整个网络就分成了几块区域，数据就散布在了这些不连通的区域中。

(3)P:Partition Tolerance 分区容错性分区容错性和扩展性紧密相关。在分布式应用中，可能因为一些分布式的原因导致系统无法正常运转。好的分区容错性要求能够使应用虽然是一个分布式系统，而看上去却好像是在一个可以运转正常的整体。比如现在的分布式系统中有某一个或者几个机器宕掉了，其他剩下的机器还能够正常运转满足系统需求，这样就具有好的分区容错性。

数据库有两个拷贝在两个不同的数据中心，当数据被写到一个数据中心的时候，他也一定要被写到另一个数据中心。那么现在假设网络中断了，这就是我们所说的网络分区的意思：

![](https://tva1.sinaimg.cn/large/007rAy9hgy1g3ftxay1ktj30u00dqab8.jpg)

目前我们可以有两个方案，应用还是被允许写到数据库，所以两边的数据库还是完全可用的。但是一旦两个数据库之间的网络中断了，任何一个数据中心的写操作就不会在另一个数据中心出现，这就违反了一致性。

如果你不想失去一致性，你就必须保证你的读写操作都在同一个数据中心，即 Leader 或者 Master 节点。另一个数据中心，因为网络故障不能被更新，就必须停止接收读写操作，直到网络恢复，两边数据库又同步了之后。所以虽然非 leader 的数据库在正常运行着，但是他却不能处理请求，这就违反了可用性定义。

# CAP 模型

CAP 理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。

![](http://mmbiz.qpic.cn/mmbiz/sXiaukvjR0RDkMrYwKrTAtVSKwpEMpjBdibvicyictt3cq9XCJE2u632L8C62Wconp2G1VKX5f4fS8qAY90BicTnvcA/640?wx_fmt=png&wxfrom=5&wx_lazy=1)

实际应用中的可用性和 CAP 可用性并不相同。你应用的可用性多数是通过 SLA 来衡量的（比如 99.9%的正确的请求一定要在一秒钟之内返回成功），但是一个系统无论是否满足 CAP 可用性其实都可以满足这样的 SLA。实际操作中，跨多个数据中心的系统经常是通过异步备份(asynchronous replication)的，所以不是可线性化的。但是做出这个选择的原因经常是因为远距离网络的延迟，而不是仅仅为了处理数据中心的网络故障。

## AC 模型

AC 模型，可用性+强一致性，牺牲了分区容忍性。比如 MySQL Cluster 集群，内部还是可以用的，MySQL 集群提供两阶段提交事务方式，保证各节点数据强一致性。MySQL 的集群无法忍受脱离集群独立工作，一 旦和集群脱离了心跳，节点出问题，导致分布式事务操作到那个节点后，整个就会失败，这是 MySQL 的牺牲。

如果我们选择了 CA（一致性 + 可用性） 而放弃了 P（分区容忍性），那么当发生分区现象时，为了保证 C（一致性），系统需要禁止写入。当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A(可用性) 冲突了，因为 A（可用性）要求返回 no error 和 no timeout。因此，分布式系统理论上不可能选择 CA （一致性 + 可用性）架构，只能选择 CP（一致性 +   分区容忍性） 或者 AP （可用性 +   分区容忍性）架构，在一致性和可用性做折中选择。

## CP 模型

CP 模型，一致性+分区容忍，牺牲了可用性。因为 Node1 节点和 Node2 节点连接中断导致分区现象，Node1 节点的数据已经更新到 y，但是 Node1 和 Node2 之间的复制通道中断，数据 y 无法同步到 Node2，Node2 节点上的数据还是旧数据 x。

这时客户端 C 访问 Node2 时，Node2 需要返回 error，提示客户端 “系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。

Redis 客户端 Hash 和 Twemproxy 集群，各 Redis 节点无共享数据，所以不存在节点间的数据不 一致问题。其中节点大了，都会影响整个 Redis 集群的工作。当 Redis 某节点失效后，这个节点里的所有数据都无法访问。如果使用 3.0 Redis Cluster，它有中心管理节点负责做数据路由。

## AP 模型

同样是 Node2 节点上的数据还是旧数据 x，这时客户端 C 访问 Node2 时，Node2 将当前自己拥有的数据 x 返回给客户端了。

而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。

注意：这里 Node2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据。

![](http://mmbiz.qpic.cn/mmbiz/sXiaukvjR0RDkMrYwKrTAtVSKwpEMpjBdNdKj85GuUicGBe1kjGGuObAViblyubSibTVwnJmrG1p36VuXJNeRnyMDg/640?wx_fmt=png&wxfrom=5&wx_lazy=1)

AP 模型，可用性+分区容忍性，牺牲了强一致性。荔枝 FM 用 Cassandra 集群时，数据可以访问，数据能备份到各个节点之间，其中一个节点失效的话，数据还是可以出来的。而分布式事务的各个节点更新了提交了只是其中一部分节点，底层继续同步，这是 AP 模型。

![](http://mmbiz.qpic.cn/mmbiz/sXiaukvjR0RDkMrYwKrTAtVSKwpEMpjBd1AaqGriaCsIznuYFHsIh8QwXwedcShf0ouOlo7NTV2w3udkdBJgdXdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1)

AC 是高可用性和高强制性，所有的关系型数据库、PG 等都是强一致性，牺牲了分区容忍性。MongoDB 和 BerkeleyDB 的可用性比较差。AP 模型缺少了强一致性。

![](http://mmbiz.qpic.cn/mmbiz/sXiaukvjR0RDkMrYwKrTAtVSKwpEMpjBdgY4ReILFiaBVQXjv8q6luibPmJPKoQF5tDnmDicf13pGKjicpPcRlkwvPw/640?wx_fmt=png&wxfrom=5&wx_lazy=1)

互联网行业模型。不同的业务类型要求不同的 CAP 模型，CA 适用于支付、交易、票务等强一致性的行业，宁愿业务不可用，也不能容忍脏数据。互联网业务对于强一致性不高，发个帖子要审核，没人看到无所谓。发一个音频要进行编码审核才能看到。

# BASE

BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。

Base 模型是什么？eBay 工程师提出大规模分布式系统的实践总结，在 ACM 上发表文章提出 Bash 理论是基本可用、软状态和最终一致性。不要求实时一致性，但一定要实现最后一点。如果 ACID 为分区的数据库提供一致性的选择,那么你如何实现可用性呢?答案是 BASE(基本上可用、软(弱)状态、最终一致性).

它的核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充： CAP 理论是忽略延时的，而实际应用中延时是无法避免的。

分区期间牺牲一致性，但分区故障恢复后，系统应该达到最终一致性。

BASE 与 ACID 截然相反.ACID 比较悲观,在每个操作结束时都强制保持一致性,而 BASE 比较乐观,接受数据库的一致性处于一种动荡不定的状态.虽然,听起来很难应付,实际上这相当好管理,并且可带来 ACID 无法企及的更高级别的可伸缩性.
BASE 的可用性是通过支持局部故障而不是系统全局故障来实现的.下面是一个简单的例子:如果用户分区在 5 个数据库服务器上,BASE 设计鼓励类似的处理方式,这 样一个用户数据库的故障只会影响这台特定主机上的那 20%的用户.这里不涉及任何魔法,不过,它确实可以带来更高的可感知的系统可用性.
因 此,到目前为止,你已经将数据分解到了多个功能组中,并将最繁忙的功能组分区到了多个数据库中,如何在你的应用中应用 BASE 原则呢?与 ACID 的典型应 用场景相比,BASE 需要对逻辑事务中的操作进行更加深入的分析.到底该如何进行分析呢?后续的内容将提供部分指导原则.

- 基本可用(Basically Available)。分布式系统在故障时允许损失可用性，保证核心业务可用。音频直播或是做活动时，当业务量非常大的时候可以降级。做游戏也是，在战斗的时候最关心数值的增长，看了多少人都无所谓，缓解核心内容的压力。

- 软状态(Soft State)。允许系统中出现的中间状态，中间状态不会耽误可用性。在写代码、编程业务的设计上，必须容忍有一定的临时数据同步，考虑到全局锁和数据多版本的对比，把各个节点的相关数据都上锁，这是一个悲观锁，一旦写任务，其他人都能改我的数据，这是比较悲观的心态。

而数据多版本，类似于乐观锁，导致其他人和我方数据冲突的机会并不是那么多，只要在提交的时候发现版本不一样，更新一下，汇总数据就可以了。做好业务上的隔离，多数情况都属于多版本，技术都能解决，不一定要把所有的东西都锁死。允许有一定的临时数据。最终一致性，在临时上的数据不一样，数据同步也是要花时间的。

随着时间的迁移，不同节点的数据总是向同一个方向有一个相同的变化，这是 Bash 模型。这种模型非常适合互联网业务的发展。

![](http://mmbiz.qpic.cn/mmbiz/sXiaukvjR0RDkMrYwKrTAtVSKwpEMpjBdtO1zQY0oylPDBia3Oq1r6ic8CbUmtJicIMJyUmadEAH8BJ997DiczdOtVg/640?wx_fmt=png&wxfrom=5&wx_lazy=1)

- 最终一致性。允许窗口期数据不一致，互相关联的数据要同步。序列一致性，全局按照序列顺序来做。线性一致性，每一个时间的时钟要同步，时间序列是严格的，按顺序的。最后是强一致性，一个时间只能实行一个任务。这比较适合于互联网，所以荔枝 FM 选择了最终执行。这里的关键词是“一定时间” 和 “最终”，“一定时间”和数据的特性是强关联的，不同业务不同数据能够容忍的不一致时间是不同的。例如支付类业务是要求秒级别内达到一致，因为用户时时关注；用户发的最新微博，可以容忍 30 分钟内达到一致的状态，因为用户短时间看不到明星发的微博是无感知的。而“最终”的含义就是不管多长时间，最终还是要达到一致性的状态。

# 数据一致性模型

分布式系统通过复制数据来提高系统的可靠性和容错性，并且将数据的不同的副本存放在不同的机器上，由于维护数据副本的一致性代价很高，因此许多系统采用弱一致性来提高性能。

下面介绍常见的一致性模型：
强一致性：要求无论更新操作是在哪个数据副本上执行，之后所有的读操作都要能获得最新的数据。
对于单副本数据来说，读写操作是在同一数据上执行的，容易保证强一致性。对多副本数据来说，则需要使用分布式事务协议。
弱一致性：在这种一致性下，用户读到某一操作对系统特定数据的更新需要一段时间，我们将这段时间称为"不一致性窗口"。
最终一致性：是弱一致性的一种特例，在这种一致性下系统保证用户最终能够读取到某操作对系统特定数据的更新（读取操作之前没有该数据的其他更新操作）。
"不一致性窗口"的大小依赖于交互延迟、系统的负载，以及数据的副本数等。

系统选择哪种一致性模型取决于应用对一致性的需求，所选取的一致性模型还会影响到系统如何处理用户的请求以及对副本维护技术的选择等。

沿着 Brewer 的猜测,如果 BASE 在分区数据库中选择保留可用性(Availability), 那么,弱化一定程度的一致性就成为必然的选择.这通常难以决策,因为商业投资方与开发人员都倾向于认为一致性(Consistency)对应用的成功至关 重要.哪怕是临时的不一致也瞒不过最终用户,因此,技术部门与产品部门都需要参与进来,以决定将一致性弱化到什么程度.
图-2 是一个简单 的概要,它阐释了 BASE 中一致性要考虑的事情.用户表存储用户信息,同时还包含总销售额与总购买额.这些都是运行时的统计.交易表存储每一笔交易,将买 家、卖家以及交易金额关联在一起.这些是对实际使用的表进行过度简化后的结果,不过,它已经包含阐释一致性的多个方面的必要元素.
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig2.jpg)
一般来说,功能组之间的一致性要比功能组内部的一致性要更加容易弱化.这个示例概要包含两个功能组:用户与交易.每当售出一个条目(的商品),交易表中就会增加一条记录,买家与卖家的计数器都会被更新.使用 ACID 风格的事务,SQL 语句可能如图-3 所示.
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig3.jpg)
用户表中的总销售额的列与总购买额的列可以被认为是交易表的一份缓存(Cache).它的存在是为了提高系统的效率.有鉴于此,一致性的约束可以被 弱化. 可以调整一下买家与卖家的期望设置,从而他们的运行结余(running balance)不能立即反映交易的结果.这种情况很常见,实际上,人们经常会遇到交易与运行结余之间的这种延迟(例如,ATM 取款或者手机通话).
如何修改 SQL 语句来弱化一致性要取决于如何定义运行结余,如果它们只是简单的估计,也就是部分交易可以被错过不统计,SQL 的修改非常简单,如图-4 所示.
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig4.jpg)
现在,我们已经将对用户表与交易表的更新做了解耦.两个表之间的一致性将再也无法保证.实际上,在第一个事务与第二个事务处理间隔发生故障,将导致用户表持久处于不一致的状态,不过,如果合同约定运行时汇总(running total)是估计值的话,这样做也足够了.
如 果无法接受估计值,该怎么办呢?如何继续对用户表与交易表的更新进行解耦呢?引入一个持久消息队列来解决此问题. 有多种选择可以实现持久消息.然而,实现此消息队列的最关键的因素是,确保队列的持久化支持与数据库使用同样的资源.要实现队列在不涉及 2PC 的情况下按 事务提交,这样做很有必要 .现在的 SQL 操作看上看去有点不同了,如图-5 所示.
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig5.jpg)
这个例子中的语法有点随意,为了阐释概念对其逻辑也做了大量的简化.通过在插入语句的同一个事务中对持久消息进行排队,可以抓取更新用户运行结余所需的信息.这个事务包含在同一个数据库实例中,因此,它不会影响系统的可用性.
一 个独立的消息处理组件，会从队列中取出每条消息，并将此信息应用到用户表.这个例子看似解决了所有的问题,但是，还有一个问题没有解决.为了避免排队时发 生 2PC,消息是持久化在交易的主机上的.如果在涉及到用户主机的事务中从队列中取出消息,我们仍将遇到 2PC 的情景.
消息处理组件中的 2PC 的一种解决方案是什么都不做.通过将更新操作解耦到一个独立的后端(back-end)组件,可以保持面向客户的组件的可用性.业务需要或许可以接受较低的消息处理器的可用性.
不过,假定你的系统完全无法接受 2PC.这个问题该如何解决呢?首先,你需要理解等幂概念.如果一个操作被应用一次或多次都能取得同样的结果,就被认为是等幂的.等幂操作非常有用,因为它们允许局部故障,重复执行它们不会改变系统的最终状态.
从 等幂的角度看,所选的这个例子是有问题的.更新操作通常不等幂.这个例子中有累加账户列的操作.重复应用此操作显然会导致错误的账户余额.然而,即使是仅 仅设定一个值的更新操作也不是等幂的,因为它还涉及到操作执行的顺序.如果系统无法保证更新操作按照接收到的顺序被应用,系统的最终状态也将是不正确的. 后面的内容会进一步讨论此问题.
在账户更新的例子中,你需要一种方式来跟踪哪些更新已经应用成功,哪些更新仍然未解决.一种技术是,使用一个表来记录已经应用的那些交易的唯一识别号.
图-6 中展示的表会记录交易 ID、更新了哪个帐号以及应用此帐号的用户 ID.现在,我们的样本伪代码如图-7 所示.
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig6.jpg)
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig7.jpg)
这个例子取决于可以窥视队列中的一条消息,并在成功处理后立即删除此消息.如有必要,可以通过两个独立的事务来处理它:消息队列上一个事务,用户数据库上一个事务.数据库操作成功提交,才提交队列操作.目前的算法可以支持局部故障,而且又能提供不依赖于 2PC 的事务保证.
如果只是关注更新的顺序的话,还有一个更加简单的技术可以确保等幂更新.我们来稍微调整一下我们的示例概要,来阐释面临的挑战以及相应的解决方案(见图-8).

![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig8.jpg)
假设两笔购买交易在一个很短的时间窗口内发生,我们的消息系统无法确保顺序操作.您现在面临的情况是,取决于消息被处理的顺序,last_purchase 可能出现一个不正确的值.幸运的是,可以通过对 SQL 语句做点简单调整来解决此类更新问题, 如图-9 所描述.
![](http://deliveryimages.acm.org/10.1145/1400000/1394128/fig9.jpg)
仅仅通过不允许 last_purchase 时间做逆向调整,就可以做到更新操作顺序不相关.也可以通过这种方法来保护任何更新免遭无序更新(out-of-order update).你还可以尝试使用单调递增的事务 ID 来取代时间.

## 消息队列的顺序

关于顺序消息投递,下面这个简短地附属说明可能有用.消息系统可以提供确保消息发送的顺序与接收的顺序一致的能力.不过,支持此功能可能非常昂贵,通常也没有必要,实际上,有时它也只是给出了一种虚假的安全感.
这里提供的例子阐释了如何弱化消息的顺序,并在最终仍然能够提供一个数据库的一致性视图.弱化消息排序所需的开销是名义上的,在大部分情况下,此开销要显著的少于在消息系统中确保消息顺序的开销.
进 一步讲,无论互动风格如何,Web 应用在语义上都是一个事件驱动的系统.客户端请求以任意顺序达到系统.每个请求所需的处理时间要求也各不相同.整个系统 的不同组件的请求调度也是不确定的,导致了消息排队的不确定.要求保持消息的顺序给出的是一种虚假的安全感.简单的事实是,不确定的输入会导致不确定的输 出.

## 弱状态/最终一致性(Soft State/Eventually Consistent)

到此为止,重点一直是为了可用性而权衡牺牲部分一致性.硬币的另外一面是,理解软状态与最终一致性对应用设计有何影响.
由于软件工 程师倾向于认为系统是闭环(closed loop)的.从预见投入产生预见的产出方面讲,我们可以这样考虑他们行为的可预测性.这对于创建正确的软件系统非常必要.好的消息是,在大部分情况下使 用 BASE 不会改变一个闭环系统的可预测性,不过,它确实需要从整体上来进行审视.
一个简单的例子就可以帮助解释这一点.考虑这样一个系 统,用户可以在此将资产转移给另一个用户.哪种类型的资产都没有关系,它可以是钱或者游戏中的装备.对于这个例子,我们假设,已经通过使用一个用于解耦的 消息队列,对如下两个操作进行了解耦:从一个用户取出资产,将资产给另一个用户.
很快,系统就会感觉到有问题与不确定性.在资产离开一个用户到达另一个用户中间,有一段时间的延时. 这个时间窗口的大小由消息系统的设计所决定.无论如何,在开始状态与结束状态之间,始终会有一个时间间隔,在这段时间内, 看似任何用户都不享有这笔资产.
不 过,如果我们从用户的视角来考虑这个问题,这个时间间隔可能就是无所谓的或者根本就不存在.无论是接收的用户还是发出的用户可能都不知道资产将在何时到 达.如果在发送与接收之间的时间间隔是几秒钟,对于具体沟通资产转移的用户来讲,它将是隐蔽的或确实可以忍受的.在这种状况下,这种系统行为对用户来讲, 就是一致并可接受的,即使,我们在实现中依赖了软状态以及最终一致性.
