# 并发编程导论

随着硬件性能的迅猛发展与大数据时代的来临，并发编程日益成为编程中不可忽略的重要组成部分。简单定义来看，如果执行单元的逻辑控制流在时间上重叠，那它们就是并发（Concurrent）的。并发编程复兴的主要驱动力来自于所谓的“多核危机”。正如摩尔定律所预言的那样，芯片性能仍在不断提高，但相比加快 CPU 的速度，计算机正在向多核化方向发展。正如 Herb Sutter 所说，“免费午餐的时代已然终结”。为了让代码运行得更快，单纯依靠更快的硬件已无法满足要求，并行和分布式计算是现代应用程序的主要内容，我们需要利用多个核心或多台机器来加速应用程序或大规模运行它们。云计算承诺在所有维度上（内存、计算、存储等）实现无限的可扩展性，并发编程及其相关理论也是我们构建大规模分布式应用的基础。

![](https://i.postimg.cc/6p2GC796/image.png)

本节主要讨论并发编程理论相关的内容，可以参阅 [[Java 并发编程 https://url.wx-coder.cn/72vCj ](https://url.wx-coder.cn/72vCj)、[Go 并发编程 https://url.wx-coder.cn/FO9EX ](https://url.wx-coder.cn/FO9EX)等了解具体编程语言中并发编程的实践，可以参阅[微服务实战 https://url.wx-coder.cn/7KZ2i ](https://url.wx-coder.cn/7KZ2i)或者[关系型数据库理论 https://url.wx-coder.cn/DJNQn ](https://url.wx-coder.cn/DJNQn)了解并发编程在实际系统中的应用。

# 并发与并行

并发是同一时间应对（dealing with）多件事情的能力；并行是同一时间动手做（doing）多件事情的能力。

[![image.png](https://i.postimg.cc/N0jG91Pz/image.png)](https://postimg.cc/w1nYnszX)

并发（Concurrency）不等于并⾏（Parallelism）并发是指程序的逻辑结构；并⾏是指程序的运⾏状态；并⾏依赖硬件支持(多核)。并发是并⾏的必要条件；但并发不是并⾏的充分条件。并发只是更符合现实问题本质的表达，目的是简化代码逻辑，⽽不是使程序运⾏更快。要是程序运⾏更快必是并发程序+多核并⾏。并发是问题域中的概念——程序需要被设计成能够处理多个同时(或者几乎同时)发生的事件；一个并发程序含有多个逻辑上的独立执行块，它们可以独立地并行执行，也可以串行执行。而并行则是方法域中的概念——通过将问题中的多个部分并行执行，来加速解决问题。一个并行程序解决问题的速度往往比一个串行程序快得多，因为其可以同时执行整个任务的多个部分。并行程序可能有多个独立执行块，也可能仅有一个。

具体而言，Redis 会是一个很好地区分并发和并行的例子。Redis 本身是一个单线程的数据库，但是可以通过多路复用与事件循环的方式来提供并发地 IO 服务。这是因为多核并行本质上会有很大的一个同步的代价，特别是在锁或者信号量的情况下。因此，Redis 利用了单线程的事件循环来保证一系列的原子操作，从而保证了即使在高并发的情况下也能达到几乎零消耗的同步。再引用下 Rob Pike 的描述：

> A single-threaded program can definitely provides concurrency at the IO level by using an IO (de)multiplexing mechanism and an event loop (which is what Redis does).

## 并行架构（Parallelism）

人们通常认为并行等同于多核，但现代计算机在不同层次上都使用了并行技术。比如说，单核的运行速度现今仍能每年不断提升的原因是：单核包含的晶体管数量，如同摩尔定律预测的那 样变得越来越多，而单核在位级和指令级两个层次上都能够并行地使用这些晶体管资源。

### Bit Level | 位级并行

为什么 32 位计算机比 8 位计算机运行速度更快？因为并行。对于两个 32 位数的加法，8 位计算机必须进行多次 8 位计算，而 32 位计算机可以一步完成，即并行地处理 32 位数的 4 字节。计算机的发展经历了 8 位、16 位、32 位，现在正处于 64 位时代。然而由位升级带来的性能改善是存在瓶颈的，这也正是短期内我们无法步入 128 位时代的原因。

### SIMD Level | 单指令、多数据并行

在最低的层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。例如，较新的 Intel 和 AMD 处理器都具有并行地对 4 对单精度浮点数(float)做加法的指令。提供这些 SIMD 指令多是为了提高处理影像、声音和视频数据应用的执行速度。虽然有些编译器试图从 C 程序中自动抽取出 SIDM 并行性，但是更可靠的方法是使用编译器支持的特殊向量数据类型来写程序，譬如 GCC 就支持向量数据类型。

### Instruction Level | 指令级并行

现代 CPU 的并行度很高，其中使用的技术包括流水线、乱序执行和猜测执行等。程序员通常可以不关心处理器内部并行的细节，因为尽管处理器内部的并行度很高，但是经过精心设计，从外部看上去所有处理都像是串行的。

而这种“看上去像串行”的设计逐渐变得不适用。处理器的设计者们为单核提升速度变得越来越困难。进入多核时代，我们必须面对的情况是：无论是表面上还是实质上，指令都不再串行执行了。

### Task Level | 任务级并行

从程序员的角度来看，多处理器架构最明显的分类特征是其内存模型(共享内存模型或分布式内存模型)。对于共享内存的多处理器系统，每个处理器都能访问整个内存，处理器之间的通信主要通过内存进行。

# 并发的应用场景

从计算机系统本身而言，并发被看做是操作系统内核用来运行多个应用程序的机制。很久很久以前是没有并发这个概念的，因为那个时候操作系统并不支持多任务。现在的操作系统今非昔比，支持抢占式任务、多线程、分页、TCP/IP 等现代操作系统特性，能满足用户各种各样的需求同时响应用户的不同操作，靠的是多任务系统的支持。在 Unix 时代一个进程(执行中的程序)只有一个线程，现代操作系统允许一个进程有多条线程。每个线程有独立栈空间、寄存器、程序计数器(存放下一条执行指令)。操作系统调度程序调度的是线程(在本文中提到线程的地方都指的是操作系统级的线程)，并非进程，也就是说线程才是调度的基本单位。

在单处理器系统中，一个处于运行状态的 IO 消耗型程序，例如一个网络读取阻塞或用户输入阻塞导致处理器出现空闲，在视处理器为昂贵资源的情形下，这是巨大的浪费。然后，在对称处理器中(SMP)，因为只有一个线程，那它只能在其中一个处理器上运行，也就是说剩余的处理器被白白浪费。如果使用多线程，不仅能充分利用多处理器，还能通过线程并发解决上述 IO 消耗程序中处理器空闲问题。并发编程能够解决的典型问题如下所示：

```c
while (true){
     request = next_http_request()
     request_work(request)
}
```

当 request_work 发起 IO 之后 CPU 是完全空闲下来的，而可怜的新请求(next_http_request)必须等待 IO 完成之后才可以获取 CPU 的控制权。所以 CPU 的利用率非常低，并发要解决的问题就是提高 CPU 的利用率。明白这一点我们也就清楚了，并发只对非 CPU 密集型程序管用，如果 CPU 利用率非常高，更多的并发只会让情况更加糟糕。并发虽好，也不能滥用啊，典型的并发编程的适用场景包括:

- 在多处理器上进行并行计算：在只有一个 CPU 的单处理器上, 井发流是交替的。在任何时间点上, 都只有一个流在 CPU 上实际执行。 然而, 那些有多个 CPU 的机器, 称为多处理器, 可以真正地同时执行多个流。被分成并发流的并发应用 在这样的机器上能够运行得快很多，这对大规模数据库和科学应用尤为重要。

- 访问慢速 IO 设备：当一个应用正在等待来自慢速 IO 设备 (例如磁盘) 的数据到达时，内核会运行其他进程使 CPU 保持繁忙。 每个应用都可以以类似的方式，通过交替执行 IO，请求和其他有用的工作来使用并发性。

- 与人交互：和计算机交互的人要求计算机同时执行多个任务的能力。 例如, 他们在打印个文档时, 可能想要调整一个窗口的大伽 现代视窗系统利用并发性来提供这种能九 每次用户请求某种操作 忧匕如说通过单击鼠标) 时, 一个独立的并发逻辑流被创建来执行这个操作。

- 通过推迟工作以减少执行时延：有时, 应用程序能够通过推迟其他操作井同时执行它们,利用并发性来降低某些操作的延遮 比如, ˉ 一个动态存储分配器可以通过椎迟与酬个运行在较低优先级上的并发 “合井” 流的合并 (coalescing), 使用空闲时的 CPU 周期, 来降低单个 free 操作的延迟。

- 服务多个网络客户端：一个慢速的客户端可能会导致服务器拒绝为所有其他客户端服务。 对于闻个真正的服务器来说 可能期望它每秒为成百上千的客户端提供服务, 某些个慢速客户端寻致拒绝为其他客户端服务, 这是不能接受峋 一个更好的方法是创建一个并发服务糕 它为每个客户端创建各自独立的逻辑流 这就允许服务器同时为多个客户端服务, 并且这也避免了慢速客户端独占服务器。

# Amdahl 定律

Amdahl 定律可以用来计算处理器平行运算之后效率提升的能力，其由 Gene Amdal 在 1967 年提出；它描述了在一个系统中，基于可并行化和串行化的组件各自所占的比重，程序通过获得额外的计算资源，理论上能够加速多少。任何程序或算法可以按照是否可以被并行化分为可以被并行化的部分 `1 - B` 与不可以被并行化的部分 B，那么根据 Amdahl 定律，不同的并行因子的情况下程序的总执行时间的变化如下所示：

![](https://coding.net/u/hoteam/p/Cache/git/raw/master/2017/8/3/2321312312.png)

如果 F 是必须串行化执行的比重，那么 Amdahl 定律告诉我们，在一个 N 处理器的机器中，我们最多可以加速：

![](https://coding.net/u/hoteam/p/Cache/git/raw/master/2017/8/3/111111111.png)

当 N 无限增大趋近无穷时，speedup 的最大值无限趋近 `1/F`，这意味着一个程序中如果 50% 的处理都需要串行进行的话，speedup 只能提升 2 倍(不考虑事实上有多少线程可用)；如果程序的 10% 需要串行进行，speedup 最多能够提高近 10 倍。

![](http://hi.csdn.net/attachment/201004/22/0_1271944737VpZC.gif)

Amdahl 定律同样量化了串行化的效率开销。在拥有 10 个处理器的系统中，程序如果有 10% 是串行化的，那么最多可以加速 5.3 倍(53 ％的使用率)，在拥有 100 个处理器的系统中，这个数字可以达到 9.2(9 ％的使用率)。这使得无效的 CPU 利用永远不可能到达 10 倍。下图展示了随着串行执行和处理器数量变化，处理器最大限度的利用率的曲线。随着处理器数量的增加，我们很明显地看到，即使串行化执行的程度发 生细微的百分比变化，都会大大限制吞吐量随计算资源增加。

Amdahl 定律旨在说明，多核 CPU 对系统进行优化时，优化的效果取决于 CPU 的数量以及系统中的串行化程序的比重；如果仅关注于提高 CPU 数量而不降低程序的串行化比重，也无法提高系统性能。

# 链接
