# 流计算

分布式的流处理也就是通常意义上的持续处理、数据富集以及对于无界数据的分析过程的组合。它是一个类似于 MapReduce 这样的通用计算模型，但是我们希望它能够在毫秒级别或者秒级别完成响应。这些系统经常被有向非循环图(Directed ACyclic Graphs,DAGs)来表示。

# 批处理与流计算

Flink、Beam 等都支持“流式处理优先，将批处理视为流式处理的特殊情况”的理念，这个理念也经常被认为是构建跨实时和离线数据应用程序的强大方式，可以大大降低数据基础设施的复杂性。“批处理只是流式处理的一个特例”并不意味着所有的流式处理器都能用于批处理——流式处理器的出现并没有让批处理器变得过时：  

- 纯流式处理系统在批处理工作负载时其实是很慢的。没有人会认为使用流式处理器来分析海量数据是个好主意。

- 像 Apache Beam 这样的统一 API 通常会根据数据是持续的（无界）还是固定的（有界）将工作负载委托给不同的运行时。

- Flink 提供了一个流式 API，可以处理有界和无界的场景，同时仍然提供了单独的 DataSet API 和运行时用于批处理，因为速度会更快。

# DataFlow 模型

Dataflow模型（或者说Beam模型）旨在建立一套准确可靠的关于流处理的解决方案。在Dataflow模型提出以前，流处理常被认为是一种不可靠但低延迟的处理方式，需要配合类似于MapReduce的准确但高延迟的批处理框架才能得到一个可靠的结果，这就是著名的Lambda架构。这种架构给应用带来了很多的麻烦，例如引入多套组件导致系统的复杂性、可维护性难度提高。因此Lambda架构遭到很多开发者的炮轰，并试图设计一套统一批流的架构减少这种复杂性。Spark 1.X的Mirco-Batch模型就尝试从批处理的角度处理流数据，将不间断的流数据切分为一个个微小的批处理块，从而可以使用批处理的transform操作处理数据。还有Jay提出的Kappa架构，使用类似于Kafka的日志型消息存储作为中间件，从流处理的角度处理批处理。在工程师的不断努力和尝试下，Dataflow模型孕育而生。



# 链接

