> [关系型数据库中事务与并发控制详解]()

# 事务与并发控制

数据库事务具有 ACID 属性，即原子性(Atomic )、一致性(Consistency )、隔离性(Isolation )、持久性(Durability )，为针对数据库的一系列操作提供了一种从失败状态恢复到正常状态的方法，使数据库在异常状态下也能够保持数据的一致性，且面对并发访问时，数据库能够提供一种隔离方法，避免彼此间的操作互相干扰。

数据库事务由具体的 DBMS 系统来保障操作的原子性，同一个事务当中，如果有某个操作执行失败，则事务当中的所有操作都需要进行回滚，回到事务执行前的状态。导致事务失败的原因有很多，可能是因为修改不符合表的约束规则，也有可能是网络异常，甚至是存储介质故障等，而一旦事务失败，则需要对所有已作出的修改操作进行还原，使数据库的状态恢复到事务执行前的状态，以保障数据的一致性，使修改操作要么全部成功、要么全部失败，避免存在中间状态[5]。

为了实现数据库状态的恢复，DBMS 系统通常需要维护事务日志以追踪事务中所有影响数据库数据的操作，以便执行失败时进行事务的回滚。以 MySQL 的 innodb 存储引擎为例，innodb 存储引擎通过预写事务日志[6]的方式，来保障事务的原子性、一致性以及持久性。它包含 redo 日志和 undo 日志，redo 日志在系统需要的时候，对事务操作进行重做，如当系统宕机重启后，能够对内存中还没有持久化到磁盘的数据进行恢复，而 undo 日志，则能够在事务执行失败的时候，利用这些 undo 信息，将数据还原到事务执行前的状态。

事务日志可以提高事务执行的效率，存储引擎只需要将修改行为持久到事务日志当中，便可以只对该数据在内存中的拷贝进行修改，而不需要每次修改都将数据回写到磁盘。这样做的好处是，日志写入是一小块区域的顺序 I/O，而数据库数据的磁盘回写则是随机 I/O，磁头需要不停地移动来寻找需要更新数据的位置，无疑效率更低，通过事务日志的持久化，既保障了数据存储的可靠性，又提高了数据写入的效率。

# 锁



# 锁
 业务逻辑的实现过程中，往往需要保证数据访问的排他性。如在金融系统的日终结算处理中，我们希望针对某个 cut-off 时间点的数据进行处理，而不希望在结算进行过程中(可能是几秒种，也可能是几个小时)，数据再发生变化。此时，我们就需要通过一些机制来保证这些数据在某个操作过程中不会被外界修改，这样的机制，在这里，也就是所谓的 “ 锁 ” ，即给我们选定的目标数据上锁，使其无法被其他程序修改。Hibernate 支持两种锁机制：即通常所说的 “ 悲观锁( Pessimistic Locking ) ”和 “ 乐观锁( Optimistic Locking ) ” 。
当执行事务时，相当于执行了锁，来保持数据的一致性，但是锁分多种，有行锁，表锁。行锁就是只锁定那一行，那一条记录，别的连接下的操作还可以操作这张表。表锁就是锁定整张表，只有当前连接执行完事务，才可以解锁。
 
就效率而然，当然是行锁好，适用与多线程和高并发的情况，不过行锁对数据库会带来额外的开销。表锁高并发就差一点了，但单个的话快一点。
 
以mysql为例，有索引并且使用了该索引当条件的时候就是行锁，没有索引的时候就是表锁。innodb 的行锁是在有索引的情况下,没有索引的表是锁定全表的.
 
锁是对于别的连接来说，不是对于当前连接，即当前连可以一直不加rollback，commit，一路更新，但是别的连接就不行，必须等加了锁的连接释放(rollback，commit)后才能更新，插入
 
建议：对于插入操作，一般加表锁，但是对于修改和删除操作，最好加行锁，这样在高并发时，不用等太久
 
加锁方式：
select * from testlock where id=1 for update;——查询加锁，查询时不允许更改，该语句在自动提交为off或事务中生效，相当于更改操作，模拟加锁
update testlock name=name;——列=同一个列
更新操作，插入，删除操作，在事务中均属于加锁


## 并发策略
### 悲观锁( Pessimistic Locking )
 悲观锁，正如其名，它指的是对数据被外界(包括本系统当前的其他事务，以及来自
外部系统的事务处理)修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定
状态。悲观锁的实现，往往依靠数据库提供的锁机制(也只有数据库层提供的锁机制才能
真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系
统不会修改数据)。
一个典型的倚赖数据库的悲观锁调用：
select * from account where name=”Erica” for update
这条 sql 语句锁定了 account 表中所有符合检索条件( name=”Erica” )的记录。
本次事务提交之前(事务提交时会释放事务过程中的锁)，外界无法修改这些记录。
Hibernate 的悲观锁，也是基于数据库的锁机制实现。
注意，只有在查询开始之前(也就是 Hiberate 生成 SQL 之前)设定加锁，才会
真正通过数据库的锁机制进行加锁处理，否则，数据已经通过不包含 for update
子句的 Select SQL 加载进来，所谓数据库加锁也就无从谈起。

### 乐观锁( Optimistic Locking )

 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依
靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库
性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。
如一个金融系统，当某个操作员读取用户的数据，并在读出的用户数据的基础上进
行修改时(如更改用户帐户余额)，如果采用悲观锁机制，也就意味着整个操作过
程中(从操作员读出数据、开始修改直至提交修改结果的全过程，甚至还包括操作
员中途去煮咖啡的时间)，数据库记录始终处于加锁状态，可以想见，如果面对几
百上千个并发，这样的情况将导致怎样的后果。
乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本
( Version )记录机制实现。何谓数据版本？即为数据增加一个版本标识，在基于
数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来
实现。
读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提
交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据
版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。
对于上面修改用户帐户信息的例子而言，假设数据库中帐户信息表中有一个
version 字段，当前值为 1 ；而当前帐户余额字段( balance )为 $100 。
1 操作员 A 此时将其读出( version=1 )，并从其帐户余额中扣除 $50
( $100-$50 )。
2 在操作员 A 操作的过程中，操作员 B 也读入此用户信息( version=1 )，并
从其帐户余额中扣除 $20 ( $100-$20 )。
3 操作员 A 完成了修改工作，将数据版本号加一( version=2 )，连同帐户扣
除后余额( balance=$50 )，提交至数据库更新，此时由于提交数据版本大
于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
4 操作员 B 完成了操作，也将版本号加一( version=2 )试图向数据库提交数
据( balance=$80 )，但此时比对数据库记录版本时发现，操作员 B 提交的
数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记
录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。
这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作
员 A 的操作结果的可能。
从上面的例子可以看出，乐观锁机制避免了长事务中的数据库加锁开销(操作员 A
和操作员 B 操作过程中，都没有对数据库数据加锁)，大大提升了大并发量下的系
统整体性能表现。
需要注意的是，乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局
限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户
余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。在
系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整(如
将乐观锁策略在数据库存储过程中实现，对外只开放基于此存储过程的数据更新途
径，而不是将数据库表直接对外公开)。


# Transaction: 事务

## ACID

ACID 数据库事务极大地简化了应用开发人员的工作 . 正如其缩写标识所示 ,ACID 事务提供以下几种保证 :

* **原子性 (Atomicity)**. 事务中的所有操作 , 要么全部成功 , 要么全部不做 .
* **一致性 (Consistency)**. 在事务开始与结束时 , 数据库处于一致状态 .
* **隔离性 (Isolation)**. 事务如同只有这一个操作在被数据库所执行一样 .
* **持久性 (Durability)**. 在事务结束时 , 此操作将不可逆转 .( 也就是只要事务提交 , 系统将保证数据不会丢失 , 即使出现系统 Crash, 译者补充 ).

对于 ACID 的实现方式主要有两个，一个是日志式的方式(Write ahead logging )，几乎所有的数据库系统(MySQL 、 Oracle 等)都基于日志的方式。另外一种是 Shadow paging，代表的数据库主要是 SQLite，Android 或者 iOS APP 开发的话应该会比较了解，但大型的数据库都不会用到。 ![](http://mmbiz.qpic.cn/mmbiz/Pn4Sm0RsAujF1Uh53H2CzRNHKIzAkSZbyqPPFjQhgY2l6llddIVKZBCkEmoH8VYWO9HRSSZ1RcvmjTPl987CwA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)

数据库厂商在很久以前就认识到数据库分区的必要性 , 并引入了一种称为 2PC( 两阶段提交 ) 的技术来提供跨越多个数据库实例的 ACID 保证 . 这个协议分为以下两个阶段 :

* 第一阶段 , 事务协调器要求每个涉及到事务的数据库预提交 (precommit) 此操作 , 并反映是否可以提交 .
* 第二阶段 , 事务协调器要求每个数据库提交数据 .

如果有任何一个数据库否决此次提交 , 那么所有数据库都会被要求回滚它们在此事务中的那部分信息 . 这样做的缺陷是什么呢 ? 我们可以在分区之间获得一致性 . 如果 Brewer 的猜测是对的 , 那么我们一定会影响到可用性 , 但 , 怎么可以这样呢 ?

任何系统的可用性都是执行操作的相关组件的可用性的产物 . 此陈述的后半段尤其重要 . 系统中可能会使用但又不是必需的组件 , 不会降低系统的可用性 . 在两阶段提交中涉及到两个数据库的事务 , 它的可用性是这两个数据库中每一个的可用性的产物 . 例如 , 如果我们假设每个数据库都有为 99.9% 的可用性 , 那么这个事务的可用性就是 99.8%, 或者说每月 43 分钟的额外停机时间 .

## 隔离级别

SQL 标准定义了 4 类隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。

* **Read Uncommitted (未提交读)：** 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。**读取未提交的数据，也被称之为脏读(Dirty Read )。**

- **Read Committed (提交读)：**这是大多数数据库系统的默认隔离级别(但不是[MySQL](http://lib.csdn.net/base/14)默认的)。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的**不可重复读(Nonrepeatable Read )**，因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一查询可能返回不同结果。

* **Repeatable Read (可重复读)：**这是 MySQL 的默认事务隔离级别，它确保在一个事务内的相同查询条件的多次查询会看到同样的数据行，都是事务开始时的数据快照。不过理论上，这会导致另一个棘手的问题：**幻读 (Phantom Read )**，怎么理解幻读？简单说，就是当某个事务在读取某个范围内的记录时， 另外的一个事务又在该范围内插入新的记录。在之前的事务在读取该范围的记录时，就会产生幻行。( InnoDB 通过间隙锁(next-key locking )策略防止幻读的出现)

- **Serializable (可串行化)：**这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

| 离级别                        | 脏读(Dirty Read ) | 不可重复读(NonRepeatable Read ) | 幻读(Phantom Read ) |
| ----------------------------- | ------------------- | --------------------------------- | --------------------- |
| 未提交读(Read uncommitted ) | 可能                | 可能                              | 可能                  |
| 提交读(Read committed )     | 不可能              | 可能                              | 可能                  |
| 可重复读(Repeatable read )  | 不可能              | 不可能                            | 可能                  |
| 可串行化(Serializable )     | 不可能              | 不可能                            | 不可能                |

### Read uncommitted 读未提交

公司发工资了，领导把 5000 元打到 singo 的账号上，但是该事务并未提交，而 singo 正好去查看账户，发现工资已经到账，是 5000 元整，非常高兴。可是不幸的是，领导发现发给 singo 的工资金额不对，是 2000 元，于是迅速回滚了事务，修改金额后，将事务提交，最后 singo 实际的工资只有 2000 元，singo 空欢喜一场。

![img](http://dl.iteye.com/upload/attachment/556524/f244ae46-c8f4-3bc1-906e-d1d9c1af3516.gif)

出现上述情况，即我们所说的脏读，两个并发的事务，“ 事务 A：领导给 singo 发工资 ”、“ 事务 B：singo 查询工资账户 ”，事务 B 读取了事务 A 尚未提交的数据。

当隔离级别设置为 Read uncommitted 时，就可能出现脏读，如何避免脏读，请看下一个隔离级别。

### Read committed 读提交

singo 拿着工资卡去消费，系统读取到卡里确实有 2000 元，而此时她的老婆也正好在网上转账，把 singo 工资卡的 2000 元转到另一账户，并在 singo 之前提交了事务，当 singo 扣款时，系统检查到 singo 的工资卡已经没有钱，扣款失败，singo 十分纳闷，明明卡里有钱，为何 ......

出现上述情况，即我们所说的不可重复读，两个并发的事务，“ 事务 A：singo 消费 ”、“ 事务 B：singo 的老婆网上转账 ”，事务 A 事先读取了数据，事务 B 紧接了更新了数据，并提交了事务，而事务 A 再次读取该数据时，数据已经发生了改变。

当隔离级别设置为 Read committed 时，避免了脏读，但是可能会造成不可重复读。

大多数数据库的默认级别就是 Read committed，比如 Sql Server , Oracle。如何解决不可重复读这一问题，请看下一个隔离级别。

### Repeatable read 重复读

不可重复读是指事务 T1 读取数据后，事务 T2 执行更新操作，使 T1 无法再现前一次读取结果。具体地讲，不可重复读包括三种情况：

事务 T1 读取某一数据后，事务 T2 对其做了修改，当事务 1 再次读该数据时，得到与前一次不同的值。例如，T1 读取 B=100 进行运算，T2 读取同一数据 B，对其进行修改后将 B=200 写回数据库。T1 为了对读取值校对重读 B，B 已为 200，与第一次读取值不一致。

事务 T1 按一定条件从数据库中读取了某些数据记录后，事务 T2 删除了其中部分记录，当 T1 再次按相同条件读取数据时，发现某些记录神密地消失了。 事务 T1 按一定条件从数据库中读取某些数据记录后，事务 T2 插入了一些记录，当 T1 再次按相同条件读取数据时，发现多了一些记录。(这也叫做幻影读)

当隔离级别设置为 Repeatable read 时，可以避免不可重复读。当 singo 拿着工资卡去消费时，一旦系统开始读取工资卡信息(即事务开始)， singo 的老婆就不可能对该记录进行修改，也就是 singo 的老婆不能在此时转账。

虽然 Repeatable read 避免了不可重复读，但还有可能出现幻读。

singo 的老婆工作在银行部门，她时常通过银行内部系统查看 singo 的信用卡消费记录。有一天，她正在查询到 singo 当月信用卡的总消费金额(select sum(amount) from transaction where month = 本月)为 80 元，而 singo 此时正好在外面胡吃海塞后在收银台买单，消费 1000 元，即新增了一条 1000 元的消费记录(insert transaction ... )，并提交了事务，随后 singo 的老婆将 singo 当月信用卡消费的明细打印到 A4 纸上，却发现消费总额为 1080 元，singo 的老婆很诧异，以为出现了幻觉，幻读就这样产生了。

注：[MySQL](http://lib.csdn.net/base/14)行锁的默认隔离级别就是 Repeatable read。

### Serializable 序列化

Serializable 是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。

# Concurrency Control: 并发控制

当多个用户 ( 多事务 ) 同时访问和修改数据的时候，如何能保证用户读取数据的一致性 ? 我们常常用到一种机制称为：**并发控制 (Concurrency Control)** 　　在大多数据库中，**锁 (Lock)** 是并发控制的核心机制之一，锁管理着数据库资源的并发访问，并且防止多用户 ( 多事务 ) 之间 “ 相互干涉 ”。下面我们总结一下数据库中常用的锁： 从对数据操作的类型(读 \ 写)来看分为：

**读锁(共享锁)：**针对同一块数据，多个读操作可以同时进行而不会互相影响。

**写锁(排他锁)：**当当前写操作没有完成前，它会阻断其他写锁和读锁。 从锁定的数据范围(锁粒度(Lock granularity ))来看分为：

**表锁：**管理锁的开销最小，同时允许的并发量也最小的锁机制。MyIsam 存储引擎使用的锁机制。当要写入数据时，把整个表都锁上，此时其他读、写动作一律等待。在 MySql 中，除了 MyIsam 存储引擎使用这种锁策略外，MySql 本身也使用表锁来执行某些特定动作，比如 ALTER TABLE.

**行锁：**可以支持最大并发的锁策略。InnoDB 和 Falcon 两张存储引擎都采用这种策略。
