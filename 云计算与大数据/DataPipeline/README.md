# Data Pipeline | 实时数据集成平台

传统的数据融合通常基于批模式。在批的模式下，我们会通过一些周期性运行的 ETL JOB，将数据从关系型数据库、文件存储向下游的目标数据库进行同步，中间可能有各种类型的转换。

![批流对比](https://tva4.sinaimg.cn/large/005R6Otmgy1g7b1zsx4q3j30ni0d6wfe.jpg)

另一种是 Data Pipeline 模式。与批模式相比相比， 其最核心的区别是将批量变为实时：输入的数据不再是周期性的去获取，而是源源不断的来自于数据库的日志、消息队列的消息。进而通过一个实时计算引擎，进行各种聚合运算，产生输出结果，并且写入下游。现代的一些处理框架，包括 Flink、Kafka Streams、Spark，或多或少都能够支持批和流两种概念。换言之，流式处理能力是实时数据集成平台必要的组件；结合企业技术栈特点，选用包括 Flink、Spark Streaming、Kafka Streams 等流行的引擎在多数情况下都能够满足要求。端到端数据的 EOS 是数据集成中的一个难题，需要用户根据业务实际需求、数据本身的特性、目的地特点 case by case 去解决。

## 系统挑战

如果问题简化到一张 MySQL 的表，里面只有几百万行数据，你可能想将其同步到一张 Hive 表中。基于这种情况，大部分问题都不会遇到。因为结构是确定的，数据量很小，且没有所谓的并行化问题。但在一个实际的企业场景下，如果做一个数据融合系统，就不可避免要面临几方面的挑战：

- 动态性: 数据源会不断地发生变化，主要归因于：表结构的变化，表的增减。针对这些情况，你需要有一些相应的策略进行处理。

- 可伸缩性: 任何一个分布式系统，必须要提供可伸缩性。因为你不是只同步一张表，通常会有大量数据同步任务在进行着。如何在一个集群或多个集群中进行统一的调度，保证任务并行执行的效率，这是一个要解决的基本问题。

- 容错性: 在任何环境里你都不能假定服务器是永远在正常运行的，网络、磁盘、内存都有可能发生故障。这种情况下一个 Job 可能会失败，之后如何进行恢复？状态能否延续？是否会产生数据的丢失和重复？这都是要考虑的问题。

- 异构性: 当我们做一个数据融合项目时，由于源和目的地是不一样的，比如，源是 MySQL，目的地是 Oracle，可能它们对于一个字段类型定义的标准是有差别的。在同步时，如果忽略这些差异，就会造成一系列的问题。

- 一致性: 一致性是数据融合中最基本的问题，即使不考虑数据同步的速度，也要保证数据一致。数据一致性的底线为：数据先不丢，如果丢了一部分，通常会导致业务无法使用；在此基础上更好的情况是：源和目的地的数据要完全一致，即所谓的端到端一致性，如何做到呢？

# Lambda 架构

Lambda 架构的核心是按需使用批量和流式的处理框架，分别针对批式和流式数据提供相应的处理逻辑。最终通过一个服务层进行对外服务的输出。与之相对，还有一种架构叫 Kappa 架构，即用一个流式处理引擎解决所有问题。我们认为 Lambda 架构是批流一体化的必然要求。

实际上，这在很大程度来自于现实中用户的需求。DataPipeline 在刚刚成立时只有一种模式，只支持实时流同步，在我们看来这是未来的一种趋势。但后来发现，很多客户实际上有批量同步的需求。比如，银行在每天晚上可能会有一些月结、日结，证券公司也有类似的结算服务。基于一些历史原因，或出于对性能、数据库配置的考虑，可能有的数据库本身不能开 change log。所以实际上并不是所有情况下都能从源端获取实时的流数据。考虑到上述问题，我们认为一个产品在支撑数据融合过程中，必须能同时支撑批量和流式两种处理模式，且在产品里面出于性能和稳定性考虑提供不同的处理策略，这才是一个相对来说比较合理的基础架构。

## 数据源

数据源变化捕获是数据集成的起点，结合日志的解析、增量条件查询模式和数据源主动 Push 模式，最终构建出一个数据汇集层。在这个阶段，推荐考虑 Kafka Connect 这类面向数据集成的专有框架，可以有效缩短研发周期和成本。数据汇集层建议构建在消息队列之上，为后继的加工处理提供便利。如果需要全量持久化长期保存，建议结合使用消息队列和分布式文件系统分别做实时数据和全量数据的存储。

