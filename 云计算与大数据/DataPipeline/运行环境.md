# 运行环境

无论采用何种数据变化捕获技术，程序必须在一个可靠的平台运行。该平台需要解决分布式系统的一些共性问题，主要包括：水平扩展、容错、进度管理等。

## 水平扩展

程序必须能够以分布式 job 的形式在集群中运行，从而允许在业务增长时通过增加运行时节点的方式实现扩展。

因为在一个规模化的企业中，通常要同时运行成百上千的 job。随着业务的增长，job 的数量以及 job 的负载还有可能持续增长。

## 容错

分布式运行环境的执行节点可能因为过载、网络连通性等原因无法正常工作。

当节点出现问题时，运行环境需要能够及时监测到，并将问题节点上的 job 分配给健康的节点继续运行。

## 进度管理

job 需要记录自身处理的进度，避免重复处理数据。另外，job 会因为上下游系统的问题、网络连通性、程序 bug 等各种原因异常中止，当 job 重启后，必须能够从上次记录的正常进度位置开始处理后继的数据。

有许多优秀的开源框架都可以满足上述要求，包括 Kafka Connect、Spark、Flink 等。

Kafka Connect 是一个专注数据进出 Kafka 的数据集成框架。Spark 和 Flink 则更为通用，既可以用于数据集成，也适用于更加复杂的应用场景，例如机器学习的模型训练和流式计算。

就数据集成这一应用场景而言，不同框架的概念是非常类似的。

首先，框架提供 Source Connector 接口封装对数据源的访问。应用开发者基于这一接口开发适配特定数据源的 Connector，实现数据抽取逻辑和进度（offset）更新逻辑。

其次，框架提供一个分布式的 Connector 运行环境，处理任务的分发、容错和进度更新等问题。

不同之处在于，Kafka Connect 总是将数据抽取到 Kafka，而对于 Spark 和 Flink，Source Connector 是将数据抽取到内存中构建对象，写入目的地是由程序逻辑定义的，包括但不限于消息队列。

但无论采用何种框架，都建议首先将数据写入一个汇集层，通常是 Kafka 这样的消息队列。单就数据源采集而言，Kafka Connect 这样专注于数据集成的框架是有一定优势的，这主要体现在两方面：

- 首先是 Connector 的丰富程度，几乎所有较为流行的数据库、对象存储、文件系统都有开源的 Connector 实现。尤其在数据库的 CDC 方面，有 Debezium 这样优秀的开源项目存在，降低了应用的成本。

- 其次是开发的便捷性，专有框架的设计相较于通用框架更为简洁，开发新的 Connector 门槛较低。Kafka Connect 的 runtime 实现也较为轻量，出现框架级别问题时 debug 也比较便捷。


